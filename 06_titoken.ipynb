{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tiktoken\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"p50k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc.encode(\"Hello World\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string:str, model_name:str=\"p50k_base\"):\n",
    "    enc = tiktoken.get_encoding(model_name)\n",
    "    return len(enc.encode(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539\n"
     ]
    }
   ],
   "source": [
    "string = \"\"\"\n",
    "import openai\n",
    "from dotenv import dotenv_values\n",
    "import argparse\n",
    "\n",
    "# Load OpenAI API key from .env file\n",
    "config = dotenv_values(\".env\")\n",
    "openai.api_key = config[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Define functions to print colored text\n",
    "def print_bold(text):\n",
    "    return f\"\\033[1m{text}\\033[0m\"\n",
    "\n",
    "def print_red(text):\n",
    "    return f\"\\033[31m{text}\\033[0m\"\n",
    "\n",
    "def print_blue(text):\n",
    "    return f\"\\033[34m{text}\\033[0m\"\n",
    "\n",
    "def main():\n",
    "    # Parse command line arguments\n",
    "    parser = argparse.ArgumentParser(description='Simple command line chatbot')\n",
    "    parser.add_argument(\"--personality\", type=str, default=\"friendly helpful\", help=\"Personality of the chatbot\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Print command line arguments\n",
    "    print(f\"Starting chatbot with personality: {args.personality}\")\n",
    "\n",
    "    # Initialize chatbot messages\n",
    "    initial_prompt = f\"You are a conversational chatbot. Your personality is {args.personality}\"\n",
    "    messages = [{\"role\": \"system\", \"content\": initial_prompt}]\n",
    "\n",
    "    # Start chatbot loop\n",
    "    while True:\n",
    "        try:\n",
    "            # Get user input\n",
    "            user_input = input(f\"{print_blue(print_bold('You:'))} \")\n",
    "            messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "            # Get chatbot response from OpenAI API\n",
    "            res = openai.ChatCompletion.create(\n",
    "                model=\"davinci\",\n",
    "                messages=messages)\n",
    "\n",
    "            bot_answer = res.choices[0].text\n",
    "            print(f\"{print_red(print_bold('Bot:'))} {bot_answer}\\n\")\n",
    "            messages.append({\"role\": \"assistant\", \"content\": bot_answer})\n",
    "\n",
    "        except (KeyboardInterrupt, EOFError):\n",
    "            # Handle keyboard interrupt or end of file\n",
    "            print(\"\\nExiting...\")\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle other exceptions\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(num_tokens_from_string(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found.\")\n",
    "        return None\n",
    "    num_tokens = 0\n",
    "    tokens_per_message = 2 # for message start and end tokens\n",
    "    tokens_per_name = 1 # for name token\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    return num_tokens\n",
    "\n",
    "# Example usage\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "]\n",
    "model = \"gpt-3.5-turbo-0301\"\n",
    "num_tokens = num_tokens_from_messages(messages, model)\n",
    "print(num_tokens) # prints 28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
